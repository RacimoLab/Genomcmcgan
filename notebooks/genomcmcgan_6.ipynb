{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "genomcmcgan_6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJrCbN0cjl90"
      },
      "source": [
        "Python script to run MCMC-GAN inference on simulated data to predict multiple demographic parameters jointly.\n",
        "\n",
        "Installation of the required libraries:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8MM935TkE5j"
      },
      "source": [
        "%%capture\n",
        "# Installing required libraries\n",
        "!apt-get install python-dev libgsl0-dev\n",
        " \n",
        "# The latest version of tskit 0.3 gives problem with msprime\n",
        "!pip install tskit==0.2.3 zarr msprime stdpopsim tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCKcPq5zNUQ8"
      },
      "source": [
        "Import the necessary libraries and GPU settings:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHv7M0ScGM6n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcc3bc3b-9dfb-46c6-f13d-ec16e7c7057e"
      },
      "source": [
        "# Importing libraries and modules\n",
        "import msprime\n",
        "import stdpopsim\n",
        "import zarr\n",
        "import random\n",
        "import pickle\n",
        "import imageio\n",
        "import bisect\n",
        "import time\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "from tensorflow import keras\n",
        "import tensorflow_probability as tfp\n",
        "print(tfp.__version__)\n",
        "import tensorflow_addons as tfa\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        " \n",
        "\n",
        "# Mount my Gdrive disk\n",
        "from google.colab import drive, files\n",
        "drive.mount('/content/gdrive')\n",
        "!mkdir /content/results\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n",
            "0.11.0\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06lwH9JGNdsK"
      },
      "source": [
        "Parameter and Genobuilder classes. The object from these classes are used to generate genotype matrices from different sources of evolutionary models or variant data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYN4Y2SYjjDp"
      },
      "source": [
        "class Parameter():\n",
        "\n",
        "    def __init__(self, name, idx, val, bounds, log=False, **kwargs):\n",
        "\n",
        "      self.name = name\n",
        "      self.idx = idx\n",
        "      if log:\n",
        "        self.val = np.float_power(10, val)\n",
        "      else:\n",
        "        self.val = val\n",
        "      self.bounds = bounds\n",
        "      self.log = log\n",
        "      super(Parameter, self).__init__(**kwargs)\n",
        "\n",
        "\n",
        "\n",
        "    def set_gauss(self, mean, std):\n",
        "\n",
        "      self.gauss_mean = mean\n",
        "      self.gauss_std = std\n",
        "\n",
        "\n",
        "\n",
        "    def rand(self):\n",
        "\n",
        "      min, max = self.bounds\n",
        "      x = np.random.uniform(min, max)\n",
        "\n",
        "      if self.log:\n",
        "        return np.float_power(10, x)\n",
        "      else:\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "    def rand_gauss(self):\n",
        "\n",
        "      if self.log:\n",
        "        return np.float_power(10, np.random.normal(\n",
        "                                self.gauss_mean, self.gauss_std))\n",
        "      else:\n",
        "        return np.random.normal(self.gauss_mean, self.gauss_std)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Genobuilder():\n",
        "    \"\"\"Class for building genotype matrices from msprime, stdpopsim\n",
        "      or empirical data read from Zarr directories, and other utilities\n",
        "      relates to these\"\"\"\n",
        "\n",
        "    def __init__(self, source, num_samples, seq_len, maf_thresh,\n",
        "                 fixed_dim = 128, scale=False, **kwargs):\n",
        "      self._num_samples = num_samples\n",
        "      self._seq_len = seq_len\n",
        "      self._maf_thresh = maf_thresh\n",
        "      self._source = source\n",
        "      self._fixed_dim = fixed_dim\n",
        "      self._scale = scale\n",
        "      self._param_bounds = None\n",
        "      self._num_reps = None\n",
        "      super(Genobuilder, self).__init__(**kwargs)\n",
        "\n",
        "\n",
        "    def set_parameters(self, sim_source, params, log=False):\n",
        "\n",
        "      self._sim_source = sim_source\n",
        "      self._params = params\n",
        "      self.log = log\n",
        "\n",
        "\n",
        "    @property\n",
        "    def num_samples(self):\n",
        "      return self._num_samples\n",
        "\n",
        "    @property\n",
        "    def seq_len(self):\n",
        "      return self._seq_len\n",
        "\n",
        "    @property\n",
        "    def maf_thresh(self):\n",
        "      return self._maf_thresh\n",
        "\n",
        "    @property\n",
        "    def source(self):\n",
        "      return self._source\n",
        "\n",
        "    @property\n",
        "    def fixed_dim(self):\n",
        "      return self._fixed_dim\n",
        "\n",
        "    @property\n",
        "    def num_reps(self):\n",
        "      return self._num_reps\n",
        "\n",
        "    @property\n",
        "    def params(self):\n",
        "      return self._params\n",
        "\n",
        "    @property\n",
        "    def sim_source(self):\n",
        "      return self._sim_source\n",
        "\n",
        "    @property\n",
        "    def scale(self):\n",
        "      return self._scale\n",
        "\n",
        "    @num_samples.setter\n",
        "    def num_samples(self, n):\n",
        "      if type(n) != int or n < 0:\n",
        "        raise ValueError('Genobuilder num_samples must be a positive integer')\n",
        "      self._num_samples = n\n",
        "\n",
        "    @maf_thresh.setter\n",
        "    def maf_thresh(self, maf):\n",
        "      if maf < 0 or maf > 1:\n",
        "        raise ValueError('The Minor Allele Frequency must be between 0 and 1')\n",
        "      self._maf_thresh = maf\n",
        "\n",
        "    @seq_len.setter\n",
        "    def seq_len(self, l):\n",
        "      self._seq_len = int(l)\n",
        "\n",
        "    @source.setter\n",
        "    def source(self, s):\n",
        "      if s not in ['msprime', 'stdpopsim', 'empirical']:\n",
        "        raise ValueError('Genobuilder source must be either msprime, '\n",
        "                         'stdpopsim or empirical')\n",
        "      self._source = s\n",
        "\n",
        "    @fixed_dim.setter\n",
        "    def fixed_dim(self, f):\n",
        "      if f % 2 != 0:\n",
        "        raise ValueError('We recommend the fixed dimension to be multiple of 2')\n",
        "      self._fixed_dim = f\n",
        "\n",
        "    @num_reps.setter\n",
        "    def num_reps(self, n):\n",
        "      self._num_reps = n\n",
        "\n",
        "\n",
        "    @params.setter\n",
        "    def params(self, p):\n",
        "      self._params = p\n",
        "\n",
        "    @sim_source.setter\n",
        "    def sim_source(self, s):\n",
        "      if s not in ['msprime', 'stdpopsim']:\n",
        "        raise ValueError('Genobuilder sim_source must be either',\n",
        "                         'msprime or stdpopsim')\n",
        "      self._sim_source = s\n",
        "\n",
        "\n",
        "\n",
        "    def simulate_msprime(self, params=None, seed=None):\n",
        "      \"\"\"Simulate demographic data, returning a tensor with n_reps number\n",
        "      of genotype matrices\"\"\"\n",
        "\n",
        "      if params == None:\n",
        "        params = self.params\n",
        "\n",
        "      sims = msprime.simulate(\n",
        "          sample_size=self.num_samples, Ne=params['effective size'].val,\n",
        "          length=self.seq_len, mutation_rate=params['mutation rate'].val,\n",
        "          recombination_rate=params['recombination rate'].val,\n",
        "          num_replicates=self.num_reps, random_seed=seed\n",
        "          )\n",
        "\n",
        "      mat = np.zeros((self.num_reps, self.num_samples, self.fixed_dim))\n",
        "\n",
        "\n",
        "      # For each tree sequence output from the simulation\n",
        "      for i, ts in enumerate(sims):\n",
        "        mat[i] = self._resize_from_ts(ts)\n",
        "\n",
        "      # Scale genotype matrices from [0, 1] to [-1, 1]. If we were to use\n",
        "      # a generator, this scale should be done with tanh function\n",
        "      if self.scale:\n",
        "        mat = scale_matrix(mat)\n",
        "\n",
        "      # Expand dimension by 1 (add channel dim). -1 stands for last axis.\n",
        "      mat = np.expand_dims(mat, axis=-1)\n",
        "\n",
        "      return mat\n",
        "\n",
        "\n",
        "\n",
        "    def simulate_msprime_generator(self, params, seed=None):\n",
        "      \"\"\"Simulate demographic data, returning a tensor with n_reps number\n",
        "      of genotype matrices\"\"\"\n",
        "\n",
        "      if self.log:\n",
        "        params = [np.float_power(10, p) for p in params]\n",
        "\n",
        "      sims = msprime.simulate(\n",
        "          sample_size=self.num_samples, Ne=params[2], length=self.seq_len,\n",
        "          mutation_rate=params[1], recombination_rate=params[0],\n",
        "          num_replicates=self.num_reps, random_seed=seed\n",
        "          )\n",
        "\n",
        "      mat = np.zeros((self.num_reps, self.num_samples, self.fixed_dim))\n",
        "\n",
        "\n",
        "      # For each tree sequence output from the simulation\n",
        "      for i, ts in enumerate(sims):\n",
        "        mat[i] = self._resize_from_ts(ts)\n",
        "\n",
        "      # Scale genotype matrices from [0, 1] to [-1, 1]. If we were to use\n",
        "      # a generator, this scale should be done with tanh function\n",
        "      if self.scale:\n",
        "        mat = scale_matrix(mat)\n",
        "\n",
        "      # Expand dimension by 1 (add channel dim). -1 stands for last axis.\n",
        "      mat = np.expand_dims(mat, axis=-1)\n",
        "\n",
        "      return mat\n",
        "\n",
        "\n",
        "\n",
        "    def _simulate_msprime_list(self, param_vals=None, seed=None, gauss=False):\n",
        "      \"\"\"Simulate demographic data, returning a tensor with n_reps number of\n",
        "      genotype matrices. Here, params is a list of values, not a single scalar\"\"\"\n",
        "\n",
        "      if gauss:\n",
        "        sims = msprime.simulate(\n",
        "            sample_size=self.num_samples,\n",
        "            Ne=self.params['effective size'].rand_gauss(),\n",
        "            length=self.seq_len,\n",
        "            mutation_rate=self.params['mutation rate'].rand_gauss(),\n",
        "            recombination_rate=self.params['recombination rate'].rand_gauss(),\n",
        "            num_replicates=self.num_reps,\n",
        "            random_seed=seed\n",
        "            )\n",
        "      else:\n",
        "        sims = msprime.simulate(\n",
        "            sample_size=self.num_samples,\n",
        "            Ne=self.params['effective size'].rand(),\n",
        "            length=self.seq_len,\n",
        "            mutation_rate=self.params['mutation rate'].rand(),\n",
        "            recombination_rate=self.params['recombination rate'].rand(),\n",
        "            num_replicates=self.num_reps,\n",
        "            random_seed=seed\n",
        "            )\n",
        "\n",
        "\n",
        "      mat = np.zeros((self.num_reps, self.num_samples, self.fixed_dim))\n",
        "\n",
        "      # For each tree sequence output from the simulation\n",
        "      for i, ts in enumerate(sims):\n",
        "        mat[i] = self._resize_from_ts(ts)\n",
        "\n",
        "      # Scale genotype matrices from [0, 1] to [-1, 1]. If we were to use\n",
        "      # a generator, this scale should be done with tanh function\n",
        "      if self.scale:\n",
        "        mat = scale_matrix(mat)\n",
        "\n",
        "      # Expand dimension by 1 (add channel dim). -1 stands for last axis.\n",
        "      mat = np.expand_dims(mat, axis=-1)\n",
        "\n",
        "      return mat\n",
        "\n",
        "\n",
        "\n",
        "    def _parse_empiricaldata(self, haplotype):\n",
        "\n",
        "      # Set up some data paths\n",
        "      mask_file = \"/content/gdrive/My Drive/mcmcgan/20140520.pilot_mask.autosomes.bed\"\n",
        "      zarr_path = \"/content/gdrive/My Drive/mcmcgan/zarr\"\n",
        "\n",
        "      # Locate the data contained in zarr\n",
        "      callset = zarr.open_group(zarr_path, mode='r')\n",
        "\n",
        "      num_samples = len(callset['1/samples'])\n",
        "\n",
        "      data = np.zeros((self.num_reps, num_samples, self.fixed_dim))\n",
        "\n",
        "      # Get lists of randomly selected chromosomes and genomic locations\n",
        "      chroms, pos, slices = self._random_sampling_geno(\n",
        "          callset, mask_file=mask_file)\n",
        "\n",
        "      # For each randomly sampled genomic location\n",
        "      for i, (chrom, pos, loc_region) in enumerate(zip(chroms, pos, slices)):\n",
        "        print(f'it {i}  :  chromosome {chrom}  :  position {pos}')\n",
        "\n",
        "        # Extract genotype and genomic position for the variants for all samples\n",
        "        gt_zarr = np.asarray(callset[f'{chrom}/calldata/GT'][loc_region])\n",
        "        pos_zarr = callset[f'{chrom}/variants/POS'][loc_region]\n",
        "        alt_zarr = callset[f'{chrom}/variants/ALT'][loc_region]\n",
        "\n",
        "        # Make sure the genome is diploid, and extract one of the haplotypes\n",
        "        assert gt_zarr.shape[2] == 2, \"Samples are not diploid\"\n",
        "        hap = self._haploidify(gt_zarr, haplotype)\n",
        "\n",
        "        # To check the number of 0s and 1s in each gt\n",
        "        # Filtering missing data by looking at -1? No -1 in 1000 genomes data.\n",
        "        #unique, counts = np.unique(hap, return_counts=True)\n",
        "        #print(dict(zip(unique, counts)))\n",
        "\n",
        "        # Get the relative position in the sequence length to resize the matrix\n",
        "        relative_pos = pos_zarr - pos\n",
        "\n",
        "        data[i] = self._resize_from_zarr(hap, relative_pos, alt_zarr)\n",
        "\n",
        "      if self.scale:\n",
        "        data = scale_matrix(data)\n",
        "\n",
        "      data = np.expand_dims(data, axis=-1)\n",
        "\n",
        "      return data\n",
        "\n",
        "\n",
        "\n",
        "    def simulate_stdpopsim(self, engine, species, model, pop,\n",
        "                            error_prob=None, seed=None):\n",
        "\n",
        "      stdengine = stdpopsim.get_engine(engine)\n",
        "      stdspecies = stdpopsim.get_species(species)\n",
        "      stdmodel = stdspecies.get_demographic_model(model)\n",
        "\n",
        "      geno = [(i, get_chrom_size(i)) for i in range(1, 23)]\n",
        "      # Sort the list by size.\n",
        "      geno.sort(key=lambda a: a[1], reverse=True)\n",
        "      cum_weights = []\n",
        "      rng = random.Random(seed)\n",
        "      for i, (chrom, size) in enumerate(geno):\n",
        "          cum_weights.append(size if i == 0 else size + cum_weights[i-1])\n",
        "\n",
        "      # The order for sampling from populations is ['YRI', 'CEU', 'CHB']\n",
        "      if pop=='YRI':\n",
        "        stdsamples = stdmodel.get_samples(self.num_samples, 0, 0)\n",
        "      elif pop=='CEU':\n",
        "        stdsamples = stdmodel.get_samples(0, self.num_samples, 0)\n",
        "      elif pop=='CHB':\n",
        "        stdsamples = stdmodel.get_samples(0, 0, self.num_samples)\n",
        "\n",
        "      sims = []\n",
        "      for i in range(self.num_reps):\n",
        "        chrom, size = rng.choices(geno, cum_weights=cum_weights)[0]\n",
        "        factor = self.seq_len/size\n",
        "        stdcontig = stdspecies.get_contig(\n",
        "            'chr' + str(chrom), length_multiplier=factor)\n",
        "        sims.append(stdengine.simulate(stdmodel, stdcontig, stdsamples))\n",
        "\n",
        "      mat = np.zeros((self.num_reps, self.num_samples, self.fixed_dim))\n",
        "\n",
        "      # For each tree sequence output from the simulation\n",
        "      for i, ts in enumerate(sims):\n",
        "\n",
        "        if type(error_prob) is float:\n",
        "          mat[i] = self._mutate_geno_old(ts, p=error_prob)\n",
        "\n",
        "        elif type(error_prob) is np.ndarray:\n",
        "          mat[i] = self._mutate_geno_old(ts, p=error_prob[i])\n",
        "\n",
        "        # No error prob, it doesn't mutate the matrix\n",
        "        else:\n",
        "          mat[i] = self._resize_from_ts(ts)\n",
        "\n",
        "\n",
        "      # Scale genotype matrices from [0, 1] to [-1, 1]. If we were to use\n",
        "      # a generator, this scale should be done with tanh function\n",
        "      if self.scale:\n",
        "        mat = scale_matrix(mat)\n",
        "\n",
        "      # Expand dimension by 1 (add channel dim). -1 stands for last axis.\n",
        "      mat = np.expand_dims(mat, axis=-1)\n",
        "\n",
        "      return mat\n",
        "\n",
        "\n",
        "\n",
        "    def generate_data(self, num_reps, paramlist=None, gauss=False):\n",
        "      #Generate (X, y) data from demographic simulations.\n",
        "\n",
        "      self.num_reps = num_reps\n",
        "\n",
        "      print(f'generating {num_reps} genotype matrices from {self.source}')\n",
        "      if self.source=='stdpopsim':\n",
        "        gen1 = self.simulate_stdpopsim(engine='msprime', species='HomSap',\n",
        "                            model='OutOfAfricaArchaicAdmixture_5R19', pop='CEU',\n",
        "                            error_prob=None)\n",
        "\n",
        "      elif self.source=='empirical':\n",
        "        gen1 = self._parse_empiricaldata(haplotype = 0)\n",
        "\n",
        "      elif self.source=='msprime':\n",
        "        gen1 = self.simulate_msprime(seed=None)\n",
        "\n",
        "      print(f'generating {num_reps} genotype matrices from {self.sim_source}')\n",
        "\n",
        "\n",
        "      print(paramlist)\n",
        "      if self.sim_source=='msprime':\n",
        "        gen0 = self._simulate_msprime_list(seed=None, gauss=gauss)\n",
        "\n",
        "      X = np.concatenate((gen1, gen0))\n",
        "      y = np.concatenate((np.ones((num_reps)), np.zeros((num_reps))))\n",
        "      print(f'X data shape is: {X.shape}')\n",
        "\n",
        "\n",
        "      #Split randomly into training and test data.\n",
        "      return train_test_split(X, y, test_size=0.1)\n",
        "\n",
        "\n",
        "\n",
        "    def generate_testdata(self, num_reps, testlist=None):\n",
        "\n",
        "      self.num_reps = num_reps\n",
        "\n",
        "      print(f'generating {num_reps} genotype matrices from ' \\\n",
        "            f'{self.sim_source} for testing')\n",
        "\n",
        "      if self.sim_source=='msprime':\n",
        "        x_test = self._simulate_msprime_list(seed=None)\n",
        "\n",
        "      return x_test\n",
        "\n",
        "\n",
        "\n",
        "    def generator_iterator(self, num_reps):\n",
        "\n",
        "      self.num_reps = num_reps\n",
        "\n",
        "      print(f'generating {num_reps} genotype matrices with different'\n",
        "            f' {self.param_name} from {self.sim_source} for testing')\n",
        "\n",
        "      if self.sim_source=='msprime':\n",
        "        x = self.simulate_msprime(seed=None)\n",
        "      if self.sim_source=='stdpopsim':\n",
        "        x = self.simulate_stdpopsim(engine='msprime', species='HomSap',\n",
        "                            model='OutOfAfricaArchaicAdmixture_5R19',\n",
        "                            pop='CEU', error_prob=p_val, seed=None)\n",
        "\n",
        "      yield x\n",
        "\n",
        "\n",
        "\n",
        "    def _mutate_geno_old(self, ts, p=0.001):\n",
        "      \"\"\"Returns a genotype matrix with a fixed number of columns,\n",
        "      as specified in x\"\"\"\n",
        "\n",
        "      rows = int(self.num_samples)\n",
        "      cols = int(self.seq_len)\n",
        "      m = np.zeros((rows, cols), dtype=float)\n",
        "\n",
        "      for variant in ts.variants():\n",
        "\n",
        "          # Filter by MAF\n",
        "          if self.maf_thresh is not None:\n",
        "              af = np.mean(variant.genotypes)\n",
        "              if af < self.maf_thresh or af > 1 - self.maf_thresh:\n",
        "                  continue\n",
        "\n",
        "          m[:, int(variant.site.position)] += variant.genotypes\n",
        "\n",
        "      m = m.flatten()\n",
        "      n = np.random.binomial(len(m), p)\n",
        "      idx = np.random.randint(0, len(m), size=n)\n",
        "      m[idx] = 1 - m[idx]\n",
        "      m = m.reshape((rows, cols))\n",
        "\n",
        "      f = int(cols/self.fixed_dim)\n",
        "      mat = np.zeros((rows, self.fixed_dim), dtype=float)\n",
        "\n",
        "      for i in range(self.fixed_dim):\n",
        "        s = i*f\n",
        "        e = s + f - 1\n",
        "        mat[:, i] = np.sum(m[:, s:e], axis=1)\n",
        "\n",
        "      return mat\n",
        "\n",
        "\n",
        "\n",
        "    def _mutate_geno(self, ts, p=0.001, flip=True):\n",
        "      \"\"\"Returns a genotype matrix with a fixed number of columns,\n",
        "      as specified in x\"\"\"\n",
        "\n",
        "      rows = int(self.num_samples)\n",
        "      cols = int(self.fixed_dim)\n",
        "      m = np.zeros((rows, cols), dtype=float)\n",
        "\n",
        "      for variant in ts.variants():\n",
        "\n",
        "          # Filter by MAF\n",
        "          if self.maf_thresh is not None:\n",
        "              af = np.mean(variant.genotypes)\n",
        "              if af < self.maf_thresh or af > 1 - self.maf_thresh:\n",
        "                  continue\n",
        "\n",
        "          # Polarise the matrix by major allele frequency.\n",
        "          if flip:\n",
        "              af = np.mean(variant.genotypes)\n",
        "              if af > 0.5 or (af == 0.5 and random.Random() > 0.5):\n",
        "                  variant.genotypes = 1 - variant.genotypes\n",
        "\n",
        "\n",
        "          n = np.random.binomial(len(variant.genotypes), p)\n",
        "          if n is not None:\n",
        "              idx = np.random.randint(0, len(variant.genotypes), size=n)\n",
        "              variant.genotypes[idx] = 1 - variant.genotypes[idx]\n",
        "\n",
        "          j = int(variant.site.position * self.fixed_dim / ts.sequence_length)\n",
        "          np.add(m[:, j], variant.genotypes, out=m[:,j],\n",
        "                 where= variant.genotypes != -1)\n",
        "\n",
        "\n",
        "      return m\n",
        "\n",
        "\n",
        "\n",
        "    def _random_sampling_geno(self, callset, mask_file = None, seed = None):\n",
        "      \"\"\"random sampling from chromosome based on the proportional\n",
        "      size and the mask\"\"\"\n",
        "\n",
        "      # Extract chromosome number and length from stdpopsim catalog\n",
        "      geno = [(i, get_chrom_size(i)) for i in range(1, 23)]\n",
        "\n",
        "      # Sort the list by size.\n",
        "      geno.sort(key=lambda a: a[1], reverse=True)\n",
        "\n",
        "      cum_weights = []\n",
        "      for i, (chrom, size) in enumerate(geno):\n",
        "          cum_weights.append(size if i == 0 else size + cum_weights[i-1])\n",
        "\n",
        "      print(\"Charging up the chromosomes\")\n",
        "      locs = [0]\n",
        "      for i in range(1, 23):\n",
        "        print(f\"Charging chromosome {i}\")\n",
        "        query = f\"{i}/variants/POS\"\n",
        "        locs.append(np.asarray(callset[query]))\n",
        "\n",
        "      mask = load_mask(mask_file, min_len = 10000) if mask_file else None\n",
        "\n",
        "      rng = random.Random(seed)\n",
        "      chroms, slices, mask_ranges, pos = [], [], [], []\n",
        "\n",
        "      while len(chroms) < self.num_reps:\n",
        "        chrom, size = rng.choices(geno, cum_weights=cum_weights)[0]\n",
        "\n",
        "        assert size > self.seq_len\n",
        "        proposal = rng.randrange(0, size - self._seq_len)\n",
        "\n",
        "        if mask:\n",
        "          for start, end in mask[str(chrom)]:\n",
        "            if start < proposal < end:\n",
        "              chroms.append(chrom)\n",
        "              pos.append(proposal)\n",
        "              slices.append(locate(\n",
        "                  locs[chrom], start=proposal, stop=proposal + self._seq_len))\n",
        "\n",
        "        else:\n",
        "          chroms.append(chrom)\n",
        "          pos.append(proposal)\n",
        "          slices.append(locate(\n",
        "              locs[chrom], start=proposal, stop=proposal + self.seq_len))\n",
        "\n",
        "      return chroms, pos, slices\n",
        "\n",
        "\n",
        "\n",
        "    def _resize_from_ts(self, ts, flip=True):\n",
        "      \"\"\"Returns a genotype matrix with a fixed number of columns,\n",
        "      as specified in size\"\"\"\n",
        "\n",
        "      m = np.zeros((ts.num_samples, self.fixed_dim), dtype=float)\n",
        "      flip = {0: 1, 1: 0, -1: -1}\n",
        "\n",
        "      for variant in ts.variants():\n",
        "\n",
        "          # Calculate allele frequency\n",
        "          af = np.mean(variant.genotypes)\n",
        "\n",
        "          # Filter by MAF\n",
        "          if self.maf_thresh is not None:\n",
        "              if af < self.maf_thresh or af > 1 - self.maf_thresh:\n",
        "                  continue\n",
        "\n",
        "          # Polarise the matrix by major allele frequency.\n",
        "          if flip:\n",
        "              if af > 0.5 or (af == 0.5 and random.Random() > 0.5):\n",
        "                  variant.genotypes = [flip[b] for b in variant.genotypes]\n",
        "\n",
        "          j = int(variant.site.position * self.fixed_dim / ts.sequence_length)\n",
        "          np.add(m[:, j], variant.genotypes, out=m[:,j],\n",
        "                 where= variant.genotypes != -1)\n",
        "\n",
        "      return m\n",
        "\n",
        "\n",
        "\n",
        "    def _resize_from_zarr(self, mat, pos, alts, flip=True):\n",
        "      \"\"\"Resizes a matrix using a sum window, given a genotype matrix,\n",
        "      positions vector,sequence length and the desired fixed size\n",
        "      of the new matrix\"\"\"\n",
        "\n",
        "      # Initialize empty matrix with the new dimensions\n",
        "      m = np.zeros((mat.shape[1], self.fixed_dim), dtype=mat.dtype)\n",
        "      flip = {0: 1, 1: 0, -1: -1}\n",
        "\n",
        "      # Fill in the resized matrix\n",
        "      for _pos, _gt, _alt in zip(pos, mat, alts):\n",
        "\n",
        "          \"\"\"\n",
        "          # Check that all the SNPs are biallelic\n",
        "          if np.count_nonzero(_alt) != 1:\n",
        "              print('found')\n",
        "              continue\n",
        "          \"\"\"\n",
        "\n",
        "          # Calculate allele frequency\n",
        "          af = np.mean(_gt)\n",
        "\n",
        "          # Filter by MAF\n",
        "          if self.maf_thresh is not None:\n",
        "              if af < self.maf_thresh or af > 1 - self.maf_thresh:\n",
        "                  continue\n",
        "\n",
        "          # Polarise the matrix by major allele frequency.\n",
        "          if flip:\n",
        "              if af > 0.5 or (af == 0.5 and random.Random() > 0.5):\n",
        "                  _gt = [flip[b] for b in _gt]\n",
        "\n",
        "          j = int(_pos * self.fixed_dim / self.seq_len) - 1\n",
        "          np.add(m[:, j], _gt, out=m[:, j], where=_gt != -1)\n",
        "\n",
        "      return m\n",
        "\n",
        "\n",
        "\n",
        "    def _haploidify(self, genmat, h):\n",
        "      \"\"\"Returns the selected haplotype from a numpy array with\n",
        "      a ploidy dimension. The parameter h must be either 0 or 1\"\"\"\n",
        "\n",
        "      if h in [0, 1, 2]:\n",
        "          if h == 2:\n",
        "            self.num_samples *= 2\n",
        "            return np.concatenate((genmat[:, :, 0], genmat[:, :, 1]))\n",
        "          else:\n",
        "            return genmat[:, :, h]\n",
        "\n",
        "      print('The parameter h must be 0 or 1 for one haplotype, or 2 for both')\n",
        "      return\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def filter_maf(gt, pos, maf):\n",
        "    \"\"\"Filter a genotype matrix gt and the SNP position vector pos in base of\n",
        "    the desired Minor Allele Frequency maf parameter\"\"\"\n",
        "\n",
        "    # Filter alleles and position where af > maf_threshold i.e. 0.05\n",
        "    af = np.mean(gt, axis=1)\n",
        "    condition = af > maf\n",
        "    gt = gt[np.array(condition), :]\n",
        "    pos = pos[condition]\n",
        "\n",
        "    # Filter alleles and position where af > 1 - maf_threshold i.e. 0.95\n",
        "    af = np.mean(gt, axis=1)\n",
        "    condition = af < 1 - maf\n",
        "    gt = gt[np.array(condition), :]\n",
        "    pos = pos[condition]\n",
        "\n",
        "    return gt, pos\n",
        "\n",
        "\n",
        "\n",
        "def load_mask(mask_file, min_len):\n",
        "      \"\"\"Given a mask file in BED format, parse the mask data and\n",
        "      returns a matrix of tuples containing the permited regions,\n",
        "      as (start, end) positions\"\"\"\n",
        "\n",
        "      # Initialize empty mask dictionary\n",
        "      mask = {str(k): [] for k in range(1, 23)}\n",
        "\n",
        "      # Read through the lines and add to the dictionary for each chrom\n",
        "      with open(mask_file, 'r') as file:\n",
        "        for line in file:\n",
        "          chrom, start, end, _ = line.split()\n",
        "          start, end = int(start), int(end)\n",
        "\n",
        "          if (end - start) > min_len:\n",
        "            mask[chrom[3:]].append((int(start), int(end)))\n",
        "\n",
        "        file.close()\n",
        "\n",
        "      return mask\n",
        "\n",
        "\n",
        "\n",
        "def get_chrom_size(chrom):\n",
        "      \"\"\"These sizes are based on the catalog for Homosapiens in stdpopsim,\n",
        "      but they're exactly the same as the one given by the VCF files,\n",
        "      so I use them for both real and simulated data\"\"\"\n",
        "\n",
        "      chrom = str(chrom)\n",
        "      length = {\n",
        "          '1': 249250621, '2': 243199373, '3': 198022430, '4': 191154276,\n",
        "          '5': 180915260, '6': 171115067, '7': 159138663, '8': 146364022,\n",
        "          '9': 141213431, '10': 135534747, '11': 135006516, '12': 133851895,\n",
        "          '13': 115169878, '14':107349540, '15': 102531392, '16': 90354753,\n",
        "          '17': 81195210, '18': 78077248,'19': 59128983, '20': 63025520,\n",
        "          '21': 48129895, '22': 51304566}\n",
        "\n",
        "      return length[chrom]\n",
        "\n",
        "\n",
        "\n",
        "def scale_matrix(mat):\n",
        "      \"\"\"Scale matrix values within [-1, 1] range\"\"\"\n",
        "      return (mat*2/np.max(mat) - 1)\n",
        "\n",
        "\n",
        "\n",
        "def draw_genmat(img, name):\n",
        "\n",
        "    plt.imshow(img, cmap=\"winter\")\n",
        "    plt.title(f'genomat_{name}')\n",
        "    plt.savefig(f'./results/genomat_{name}.png')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "def locate(sorted_idx, start=None, stop=None):\n",
        "    \"\"\"This implementation comes from scikit-allel library.\n",
        "    Change it a little for copyright lol\"\"\"\n",
        "\n",
        "    start_idx = bisect.bisect_left(sorted_idx, start) if start is not None else 0\n",
        "    stop_idx = bisect.bisect_right(sorted_idx, stop) if stop is not None else len(v)\n",
        "\n",
        "    return slice(start_idx, stop_idx)\n",
        "\n",
        "\n",
        "\n",
        "def vcf2zarr(vcf_files, pop_file, zarr_path):\n",
        "# Two veery good tutorials:\n",
        "# http://alimanfoo.github.io/2018/04/09/selecting-variants.html\n",
        "# http://alimanfoo.github.io/2017/06/14/read-vcf.html\n",
        "\n",
        "\n",
        "    # Get a list of the wanted samples from one population\n",
        "    # which are found in the VCF files\n",
        "    import pysam\n",
        "    first_vcf = pysam.VariantFile(vcf_files.replace('{n}', '1'))\n",
        "    wanted_samples = samples_from_population(pop_file)\n",
        "    found_samples = list(set(wanted_samples).intersection(\n",
        "                                              list(first_vcf.header.samples)))\n",
        "\n",
        "    # Create one zarr folder for each chromosome\n",
        "    for chrom in range(1, 23):\n",
        "      vcf = vcf_files.replace('{n}', str(chrom))\n",
        "      print(f\"Creating zarr object for chromosome {chrom}\")\n",
        "      allel.vcf_to_zarr(vcf, zarr_path, group=str(chrom), region=str(chrom),\n",
        "                        fields=['POS', 'ALT', 'samples', 'GT'],\n",
        "                        samples=found_samples, overwrite=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpr-iMZ7RTmf"
      },
      "source": [
        "Now we will build the classes and functions to build the discriminator with the permutation invariance property. \n",
        "\n",
        "- The Symmetric layer class is a type of layer that applies a summary     statistics throughout the selected axis in the input tensor, and collapses that axis dimension to 1 in the output tensor. Different summary statistics can be chosen, such as 'max', 'min', 'sum' and 'mean'.\n",
        "\n",
        "- The DMonitor and DMonitor2 classes are used to monitor the discriminator accuracy and inference power over a parameter during the training of the model.\n",
        "\n",
        "- ConfusionMatrix class is similar to the previous monitoring classes, in the sense that it also monitors the discriminator training, but plotting confusion matrices on train dataset and a given test dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gdZaoL8R7fg"
      },
      "source": [
        "In order to allow permutation invariance, the convolutional kernels have a dimension of 1xN. Also, instead of using pooling layers for downsampling, we use strides of dimensions (1,2), so the number of different rows/haplotypes remains intact, but the sequence length is halved.\n",
        "Following successful GANs tips, the network also includes Dropout, Batch Normalization and LeakyReLU activation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JiEhKjRjusBD"
      },
      "source": [
        "class Symmetric(keras.layers.Layer):\n",
        "    \"\"\"Class of keras layer from permutation invariant cnn. This layer collapses\n",
        "       the dimension specified in the given axis using a summary statistic\"\"\"\n",
        "\n",
        "    def __init__(self, function, axis, **kwargs):\n",
        "      self.function = function\n",
        "      self.axis = axis\n",
        "      super(Symmetric, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, x):\n",
        "      if self.function == 'sum':\n",
        "        out = keras.backend.sum(x, axis=self.axis, keepdims=True)\n",
        "      if self.function == 'mean':\n",
        "        out = keras.backend.mean(x, axis=self.axis, keepdims=True)\n",
        "      if self.function == 'min':\n",
        "        out = keras.backend.min(x, axis=self.axis, keepdims=True)\n",
        "      if self.function == 'max':\n",
        "        out = keras.backend.max(x, axis=self.axis, keepdims=True)\n",
        "      return out\n",
        "\n",
        "    # Without this, Its not possible to load and save the model\n",
        "    def get_config(self):\n",
        "\n",
        "      config = super().get_config().copy()\n",
        "      config.update({\n",
        "          'function': self.function,\n",
        "          'axis': self.axis,\n",
        "      })\n",
        "      return config\n",
        "\n",
        "\n",
        "class DMonitor(keras.callbacks.Callback):\n",
        "    \"\"\"Class of keras callback to use during model training. This callback\n",
        "      monitors the cnn statistical power for paramter inference, saving the\n",
        "      training results as a GIF\"\"\"\n",
        "\n",
        "\n",
        "    def __init__(self, testdata, nmod, genobuilder, it, bins=100):\n",
        "        self.testdata = testdata\n",
        "        self.nmod = nmod\n",
        "        self.genob = genobuilder\n",
        "        self.bins = bins\n",
        "        self.img_paths = []\n",
        "        self.iteration = it\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        # Get discriminator prediction function over a range of\n",
        "        # values lin parameter space\n",
        "        predictions = self.model.predict(self.testdata)\n",
        "\n",
        "        # Plot the discriminator prediction function\n",
        "        name = f'D{self.nmod}test_{self.genob.param_name}_' \\\n",
        "               f'{epoch}e_it{self.iteration}'\n",
        "        plot_average(param_values, predictions, self.genob.param_name,\n",
        "                     name, self.genob.log_scale, self.bins)\n",
        "        self.img_paths.append(f'./results/{name}.png')\n",
        "\n",
        "    def on_train_end(self, logs=None):\n",
        "        # Save the sequence of images as a gif\n",
        "        images = [imageio.imread(filename) for filename in self.img_paths]\n",
        "        imageio.mimsave(\n",
        "            f'./results/D{self.nmod}_{self.genob.param_name}_' \\\n",
        "            f'{self.genob.source}_it{self.iteration}.gif',\n",
        "            images, format='GIF', fps=5)\n",
        "\n",
        "\n",
        "\n",
        "class DMonitor2(keras.callbacks.Callback):\n",
        "    \"\"\"Class of keras callback to use during model training. This callback\n",
        "      monitors the cnn statistical power for paramter inference, saving the\n",
        "      training results as a .png\"\"\"\n",
        "\n",
        "\n",
        "    def __init__(self, param_vals, testdata, genobuilder, bins=100):\n",
        "\n",
        "        self.testdata = testdata\n",
        "        self.param_vals = param_vals\n",
        "        self.genob = genobuilder\n",
        "        self.bins = bins\n",
        "\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        # Get discriminator prediction function over a range of\n",
        "        # values lin parameter space\n",
        "        predictions = self.model.predict(self.testdata)\n",
        "\n",
        "        x, y = np.array(self.param_vals), np.array(predictions)\n",
        "\n",
        "        plotx = np.mean(x.reshape((-1, self.bins)), axis=1)\n",
        "        ploty = np.mean(y.reshape((-1, self.bins)), axis=1)\n",
        "\n",
        "        if self.genob.log_scale:\n",
        "            plt.plot(np.log10(plotx), ploty)\n",
        "        else:\n",
        "            plt.plot(plotx, ploty)\n",
        "\n",
        "        sns.set_style('darkgrid')\n",
        "        plt.ylabel('prediction D(x)')\n",
        "        plt.xlabel(f'{self.genob.param_name}')\n",
        "        plt.ylim((0, 1))\n",
        "\n",
        "\n",
        "class ConfusionMatrix(keras.callbacks.Callback):\n",
        "    \"\"\"Class of keras callback to use during model training. This callback\n",
        "       monitors the cnn statistical power by generating a Confusion Matrix\n",
        "       at the end of each epoch\"\"\"\n",
        "\n",
        "    def __init__(self, X, y, classes, cmap=plt.cm.Blues):\n",
        "\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.classes = classes\n",
        "        self.cmap = cmap\n",
        "        sns.set_style(\"white\")\n",
        "\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "\n",
        "        plt.clf()\n",
        "        pred = self.model.predict(self.X)\n",
        "        pred[pred > 0.5] = 1\n",
        "        pred[pred <= 0.5] = 0\n",
        "        cm = confusion_matrix(self.y, pred, normalize='all')\n",
        "\n",
        "        plt.imshow(cm, interpolation='nearest', cmap=self.cmap)\n",
        "\n",
        "        # Labels\n",
        "        tick_marks = np.arange(len(self.classes))\n",
        "        plt.xticks(tick_marks, self.classes, rotation=45)\n",
        "        plt.yticks(tick_marks, self.classes)\n",
        "\n",
        "        # Loop over data dimensions and create text annotations.\n",
        "        fmt = '.2f'\n",
        "        thresh = cm.max() / 2.\n",
        "        for i in range(cm.shape[0]):\n",
        "            for j in range(cm.shape[1]):\n",
        "                plt.text(j, i, f'{cm[i, j]*100:.2f}%',\n",
        "                        ha=\"center\", va=\"center\", fontsize=16,\n",
        "                        color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "        fig.tight_layout()\n",
        "        plt.xlim(-0.5, len(np.unique(self.y))-0.5)\n",
        "        plt.ylim(len(np.unique(self.y))-0.5, -0.5)\n",
        "\n",
        "        plt.colorbar()\n",
        "        plt.grid(False)\n",
        "\n",
        "        plt.ylabel('True label')\n",
        "        plt.xlabel('Predicted label')\n",
        "        plt.title('Confusion Matrix recombination rate')\n",
        "        plt.show()\n",
        "        plt.pause(0.001)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwTnElUNTTbG"
      },
      "source": [
        "Now we define the MCMC-GAN class, which allows to define a MCMC-GAN architecture with different hyperparameters that the user can choose."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsH2CUHnTRSw"
      },
      "source": [
        "class MCMCGAN():\n",
        "    \"\"\"Class for building the coupled MCMC-Discriminator architecture\"\"\"\n",
        "\n",
        "    def __init__(self, genob, kernel_name, calibrated, discriminator = None):\n",
        "        super(MCMCGAN, self).__init__()\n",
        "        self.genob = genob\n",
        "        self.discriminator = discriminator\n",
        "        self.kernel_name = kernel_name\n",
        "        self.calibrated = calibrated\n",
        "\n",
        "\n",
        "    def set_discriminator(self, cnn):\n",
        "        self.discriminator = cnn\n",
        "\n",
        "\n",
        "    def load_discriminator(self, file):\n",
        "        self.discriminator = keras.models.load_model(\n",
        "            file, custom_objects={'Symmetric': Symmetric,\n",
        "            'Addons>WeightNormalization': tfa.layers.WeightNormalization})\n",
        "\n",
        "\n",
        "    def build_discriminator(self, model, in_shape):\n",
        "      \"\"\"Build different Convnet models with permutation variance property\"\"\"\n",
        "\n",
        "      cnn = keras.models.Sequential(name='discriminator')\n",
        "\n",
        "      if model==17:\n",
        "        \"\"\"Model 16 with no BN and with Weight Normalization.\n",
        "        Paper: https://arxiv.org/pdf/1704.03971.pdf\"\"\"\n",
        "\n",
        "        cnn.add(keras.layers.BatchNormalization())\n",
        "        # None in input_shape for dimensions with variable size.\n",
        "        cnn.add(tfa.layers.WeightNormalization(\n",
        "            keras.layers.Conv2D(filters=8, kernel_size=(1, 5), padding='same',\n",
        "                                strides=(1, 2), input_shape=in_shape)))\n",
        "        cnn.add(keras.layers.LeakyReLU(0.3))\n",
        "\n",
        "        cnn.add(Symmetric('max', axis=1))\n",
        "\n",
        "        cnn.add(tfa.layers.WeightNormalization(\n",
        "            keras.layers.Conv2D(filters=16, kernel_size=(1, 5),\n",
        "                                padding='same', strides=(1, 2))))\n",
        "        cnn.add(keras.layers.LeakyReLU(0.3))\n",
        "        cnn.add(keras.layers.Dropout(0.5))\n",
        "\n",
        "        cnn.add(Symmetric('max', axis=2))\n",
        "\n",
        "\n",
        "      elif model==18:\n",
        "\n",
        "        cnn.add(keras.layers.BatchNormalization(name='BatchNorm_1'))\n",
        "        # None in input_shape for dimensions with variable size.\n",
        "        cnn.add(tfa.layers.WeightNormalization(\n",
        "            keras.layers.Conv2D(filters=32, kernel_size=(1, 5), padding='same',\n",
        "                                strides=(1, 2), input_shape=in_shape),\n",
        "                                name='Conv2D_WeightNorm_1'))\n",
        "        cnn.add(keras.layers.LeakyReLU(0.3, name='LeakyReLU_1'))\n",
        "        cnn.add(keras.layers.BatchNormalization(name='BatchNorm_2'))\n",
        "\n",
        "        cnn.add(Symmetric('sum', axis=1, name='Symmetric_1'))\n",
        "\n",
        "        cnn.add(tfa.layers.WeightNormalization(\n",
        "            keras.layers.Conv2D(filters=64, kernel_size=(1, 5),\n",
        "                                padding='same', strides=(1, 2)),\n",
        "                                name='Conv2D_WeightNorm_2'))\n",
        "        cnn.add(keras.layers.LeakyReLU(0.3, name='LeakyReLU_2'))\n",
        "        cnn.add(keras.layers.BatchNormalization(name='BatchNorm_3'))\n",
        "        cnn.add(keras.layers.Dropout(0.5, name='Dropout'))\n",
        "\n",
        "        cnn.add(Symmetric('sum', axis=2, name='Symmetric_2'))\n",
        "\n",
        "\n",
        "      elif model==19:\n",
        "\n",
        "        # None in input_shape for dimensions with variable size.\n",
        "        cnn.add(keras.layers.Conv2D(filters=32, kernel_size=(1, 5), padding='same',\n",
        "                                strides=(1, 2), input_shape=in_shape))\n",
        "        cnn.add(keras.layers.LeakyReLU(0.3))\n",
        "        cnn.add(keras.layers.BatchNormalization())\n",
        "\n",
        "        cnn.add(Symmetric('sum', axis=1))\n",
        "\n",
        "        cnn.add(keras.layers.Conv2D(filters=64, kernel_size=(1, 5),\n",
        "                                padding='same', strides=(1, 2)))\n",
        "        cnn.add(keras.layers.LeakyReLU(0.3))\n",
        "        cnn.add(keras.layers.BatchNormalization())\n",
        "        cnn.add(keras.layers.Dropout(0.5))\n",
        "\n",
        "        cnn.add(Symmetric('sum', axis=2))\n",
        "\n",
        "\n",
        "      elif model==20:\n",
        "\n",
        "        # None in input_shape for dimensions with variable size.\n",
        "        cnn.add(tfa.layers.WeightNormalization(\n",
        "            keras.layers.Conv2D(filters=32, kernel_size=(1, 5), padding='same',\n",
        "                                strides=(1, 2), input_shape=in_shape)))\n",
        "        cnn.add(keras.layers.LeakyReLU(0.3))\n",
        "        cnn.add(keras.layers.BatchNormalization())\n",
        "\n",
        "        cnn.add(Symmetric('sum', axis=1))\n",
        "\n",
        "        cnn.add(tfa.layers.WeightNormalization(\n",
        "            keras.layers.Conv2D(filters=64, kernel_size=(1, 5),\n",
        "                                padding='same', strides=(1, 2))))\n",
        "        cnn.add(keras.layers.LeakyReLU(0.3))\n",
        "        cnn.add(keras.layers.BatchNormalization())\n",
        "        cnn.add(keras.layers.Dropout(0.5))\n",
        "\n",
        "        cnn.add(Symmetric('sum', axis=2))\n",
        "\n",
        "\n",
        "      elif model=='pop_gen_cnn':\n",
        "        \"\"\"Convolutional neural network used in\n",
        "           https://github.com/flag0010/pop_gen_cnn/\"\"\"\n",
        "\n",
        "        cnn.add(keras.layers.Conv2D(128, 2, activation='relu'))\n",
        "        cnn.add(keras.layers.BatchNormalization())\n",
        "        cnn.add(keras.layers.MaxPool2D(pool_size=(2,2)))\n",
        "        cnn.add(keras.layers.Conv2D(128, 2, activation='relu'))\n",
        "        cnn.add(keras.layers.BatchNormalization())\n",
        "        cnn.add(keras.layers.MaxPool2D(pool_size=(2,2)))\n",
        "        cnn.add(keras.layers.Conv2D(128, 2, activation='relu'))\n",
        "        cnn.add(keras.layers.BatchNormalization())\n",
        "        cnn.add(keras.layers.MaxPool2D(pool_size=(2,2)))\n",
        "        cnn.add(keras.layers.Conv2D(128, 2, activation='relu'))\n",
        "        cnn.add(keras.layers.BatchNormalization())\n",
        "        cnn.add(keras.layers.MaxPool2D(pool_size=(2,2)))\n",
        "        cnn.add(keras.layers.Flatten())\n",
        "        cnn.add(keras.layers.Dense(256, activation='relu',\n",
        "                                   kernel_initializer='normal'))\n",
        "        cnn.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "        self.discriminator = cnn\n",
        "        return\n",
        "\n",
        "\n",
        "      elif model=='keras':\n",
        "        \"\"\"Discriminator used in the GAN implementation example in keras\"\"\"\n",
        "\n",
        "        cnn.add(keras.layers.Conv2D(64, (1, 7), strides=(1, 2),\n",
        "                                    padding=\"same\", input_shape=in_shape))\n",
        "        cnn.add(keras.layers.LeakyReLU(alpha=0.2))\n",
        "        cnn.add(keras.layers.Conv2D(128, (1, 7), strides=(1, 2),\n",
        "                                    padding=\"same\"))\n",
        "        cnn.add(keras.layers.LeakyReLU(alpha=0.2))\n",
        "        cnn.add(keras.layers.GlobalMaxPooling2D())\n",
        "\n",
        "\n",
        "      cnn.add(keras.layers.Flatten(name='Flatten'))\n",
        "      cnn.add(keras.layers.Dense(128, activation='relu', name='Dense'))\n",
        "      cnn.add(keras.layers.Dense(1, activation='sigmoid', name='Output_dense'))\n",
        "\n",
        "      self.discriminator = cnn\n",
        "\n",
        "\n",
        "\n",
        "    def D(self, x, num_reps=32):\n",
        "        \"\"\"\n",
        "        Simulate with parameters `x`, then classify the simulations with the\n",
        "        discriminator. Returns the average over `num_replicates` simulations.\n",
        "        \"\"\"\n",
        "\n",
        "        tf.keras.backend.clear_session()\n",
        "        self.genob.num_reps = num_reps\n",
        "\n",
        "        return tf.reduce_mean(self.discriminator.predict(\n",
        "                    self.genob.simulate_msprime_generator(x).astype(\"float32\")))\n",
        "\n",
        "\n",
        "    # D(x) is the average discriminator output from n independent\n",
        "    # simulations (which are simulated with parameters `x`).\n",
        "    def _unnormalized_log_prob(self, x):\n",
        "\n",
        "        for p in self.genob.params.values():\n",
        "          if tf.math.less(x[p.idx], p.bounds[0]) or \\\n",
        "                                    tf.math.greater(x[p.idx], p.bounds[1]):\n",
        "              print('out')\n",
        "              # We reject these parameter values by returning probability 0.\n",
        "              return -np.inf\n",
        "\n",
        "        score = self.D(x)\n",
        "        tf.print(score)\n",
        "        return tf.math.log(score)\n",
        "\n",
        "\n",
        "\n",
        "    def unnormalized_log_prob(self, x):\n",
        "        return tf.py_function(self._unnormalized_log_prob,\n",
        "                              inp=[x], Tout=tf.float32)\n",
        "\n",
        "\n",
        "\n",
        "    def setup_mcmc(self, num_mcmc_results, num_burnin_steps,\n",
        "                    initial_guess, step_size=np.float64(1.)):\n",
        "\n",
        "      # Initialize the HMC transition kernel.\n",
        "      self.num_mcmc_results = num_mcmc_results\n",
        "      self.num_burnin_steps = num_burnin_steps\n",
        "      self.initial_guess = initial_guess\n",
        "      self.samples = None\n",
        "\n",
        "      if self.kernel_name not in ['random walk', 'hmc', 'nuts']:\n",
        "          raise NameError('kernel value must be either random walk, hmc or nuts')\n",
        "\n",
        "\n",
        "      if self.kernel_name == 'random walk':\n",
        "          if self.calibrated:\n",
        "                self.mcmc_kernel = tfp.mcmc.RandomWalkMetropolis(\n",
        "                  target_log_prob_fn=self.unnormalized_log_prob)\n",
        "          else:\n",
        "                self.mcmc_kernel = tfp.mcmc.UncalibratedRandomWalk(\n",
        "                  target_log_prob_fn=self.unnormalized_log_prob)\n",
        "\n",
        "\n",
        "      elif self.kernel_name == 'hmc':\n",
        "          if self.calibrated:\n",
        "              mcmc = tfp.mcmc.HamiltonianMonteCarlo(\n",
        "                      target_log_prob_fn=self.unnormalized_log_prob,\n",
        "                      num_leapfrog_steps=3,\n",
        "                      step_size=step_size)\n",
        "          else:\n",
        "              mcmc = tfp.mcmc.UncalibratedHamiltonianMonteCarlo(\n",
        "                      target_log_prob_fn=self.unnormalized_log_prob,\n",
        "                      num_leapfrog_steps=3,\n",
        "                      step_size=step_size)\n",
        "\n",
        "          self.mcmc_kernel = tfp.mcmc.SimpleStepSizeAdaptation(\n",
        "                mcmc, num_adaptation_steps=int(self.num_burnin_steps * 0.8),\n",
        "                target_accept_prob=0.70)\n",
        "\n",
        "\n",
        "      elif self.kernel_name == 'nuts':\n",
        "          mcmc = tfp.mcmc.NoUTurnSampler(\n",
        "                  target_log_prob_fn=self.unnormalized_log_prob,\n",
        "                  step_size=step_size,\n",
        "                  max_tree_depth=10,\n",
        "                  max_energy_diff=1000.0)\n",
        "\n",
        "          self.mcmc_kernel = tfp.mcmc.DualAveragingStepSizeAdaptation(\n",
        "                mcmc, num_adaptation_steps=int(self.num_burnin_steps * 0.8),\n",
        "                step_size_setter_fn=lambda pkr,\n",
        "                new_step_size: pkr._replace(step_size=new_step_size),\n",
        "                step_size_getter_fn=lambda pkr: pkr.step_size,\n",
        "                log_accept_prob_getter_fn=lambda pkr: pkr.log_accept_ratio)\n",
        "\n",
        "\n",
        "\n",
        "    # Run the chain (with burn-in).\n",
        "    @tf.function\n",
        "    def run_chain(self):\n",
        "\n",
        "        is_accepted = None\n",
        "        log_acc_r = None\n",
        "\n",
        "        if self.kernel_name == 'random walk':\n",
        "            samples = tfp.mcmc.sample_chain(\n",
        "                  num_results=self.num_mcmc_results,\n",
        "                  num_burnin_steps=self.num_burnin_steps,\n",
        "                  current_state=self.initial_guess,\n",
        "                  kernel=self.mcmc_kernel,\n",
        "                  trace_fn=None\n",
        "                  )\n",
        "\n",
        "        elif self.kernel_name in ['hmc', 'nuts']:\n",
        "            # Run the chain (with burn-in).\n",
        "            samples, [is_accepted, log_acc_rat] = tfp.mcmc.sample_chain(\n",
        "                  num_results=self.num_mcmc_results,\n",
        "                  num_burnin_steps=self.num_burnin_steps,\n",
        "                  current_state=self.initial_guess,\n",
        "                  kernel=self.mcmc_kernel,\n",
        "                  trace_fn=lambda _, pkr: [pkr.inner_results.is_accepted,\n",
        "                                          pkr.inner_results.log_accept_ratio]\n",
        "                  )\n",
        "\n",
        "            is_accepted = tf.reduce_mean(tf.cast(is_accepted, dtype=tf.float32))\n",
        "            log_acc_r = tf.reduce_mean(tf.cast(log_acc_rat, dtype=tf.float32))\n",
        "\n",
        "        self.samples = samples\n",
        "        sample_mean = tf.reduce_mean(samples)\n",
        "        sample_stddev = tf.math.reduce_std(samples)\n",
        "\n",
        "        return sample_mean, sample_stddev, is_accepted, log_acc_r\n",
        "\n",
        "\n",
        "\n",
        "    def hist_samples(self, it, bins=10):\n",
        "\n",
        "        sns.distplot(self.samples, bins)\n",
        "        sns.set_style('darkgrid')\n",
        "        plt.title(f\"{self.kernel_name} samples distribution for iteration {it}\")\n",
        "        plt.ylabel('Frequency')\n",
        "        plt.xlabel('Parameter value')\n",
        "        plt.legend(['MCMC samples', 'Gaussian approx.'])\n",
        "        plt.savefig(f'mcmcgan_hist_it{it}.png')\n",
        "\n",
        "\n",
        "\n",
        "    def traceplot(self, it, c='r', a=.3):\n",
        "\n",
        "        sns.set_style('darkgrid')\n",
        "        plt.plot(self.samples, c=c, alpha=a)\n",
        "        plt.hlines(np.log10(genob.fixed_val), 0,\n",
        "                   self.num_mcmc_results, zorder=4, color=c)\n",
        "        plt.title(f'MCMC trace plot for iteration {it}')\n",
        "        plt.ylabel('Parameter value')\n",
        "        plt.xlabel('MCMC step')\n",
        "        plt.legend(['MCMC samples', 'real value'])\n",
        "        sns.despine(bottom=True, left=False, offset= 1)\n",
        "        plt.savefig(f'mcmcgan_trace_it{it}.png')\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def plot_average(x, y, param_name, name, log_scale, bins=10):\n",
        "\n",
        "  x, y = np.array(x), np.array(y)\n",
        "  plotx = np.mean(x.reshape((-1, bins)), axis=1)\n",
        "  ploty = np.mean(y.reshape((-1, bins)), axis=1)\n",
        "\n",
        "  if log_scale:\n",
        "    plt.plot(np.log10(plotx), ploty)\n",
        "  else:\n",
        "    plt.plot(plotx, ploty)\n",
        "\n",
        "  plt.title(name)\n",
        "  plt.ylabel('prediction D(x)')\n",
        "  plt.xlabel(param_name)\n",
        "  plt.ylim((0, 1))\n",
        "  plt.savefig(f'./results/{name}.png')\n",
        "  plt.clf()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2-3pDVymG5C"
      },
      "source": [
        "The genotype data variable `X` contains the segregating sites (SNPs) from the two simulated scenarios, which are labelled accordingly in `y`:\n",
        "\n",
        "- `y=1` for the genmat samples with the fixed parameter values to infer.\n",
        "- `y=0` for the genmat samples with random parameter values.\n",
        "\n",
        "These two variables are splitted into the training dataset (`xtrain, xval`) and the validation dataset (`ytrain, yval`).  For each independent simulation, the genotype matrix has shape (`samples, matrix_cols`). \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ore2x2S2k8SB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "outputId": "61d0a3f2-c391-43c7-d27a-36b1a604ef3b"
      },
      "source": [
        "genob = Genobuilder(\n",
        "    source='msprime',     # Source of the data with fixed parameters to infer\n",
        "    num_samples=99,       # Number of sampled haplotypes / number of rows\n",
        "    seq_len=1e6,          # Length of the randomly sampled genome region in bp\n",
        "    maf_thresh=0.05,      # Filter rare minor alleles by their frequency\n",
        "    fixed_dim=128,        # Number of columns of the genotype matrix after rescaling\n",
        "    scale=False           # Wether to scale the matrix values into [-1, 1] interval\n",
        "    )\n",
        "\n",
        "\n",
        "# For each parameter: Parameter('name', index, value, bounds, log scale)\n",
        "params_dict = {\n",
        "    'recombination rate' : Parameter('recombination rate', 0, 1.25e-9, (1e-11, 1e-7), log=False),\n",
        "    'mutation rate'      : Parameter('mutation rate', 1, 1.25e-8, (1e-9, 1e-7), log=False),\n",
        "    'effective size'     : Parameter('effective size', 2, 10000, (5000, 15000), log=False)\n",
        "}\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "params_list = [\n",
        "          Parameter('recombination rate', 0, 5e-9, (1e-9, 1e-8)),\n",
        "          Parameter('mutation rate', 1, 5e-8, (1e-8, 9e-8)),\n",
        "          Parameter('effective size', 2, 10000, (5000, 15000))\n",
        "]\n",
        "\"\"\"\n",
        "\n",
        "genob.set_parameters(\n",
        "    sim_source = 'msprime',\n",
        "    params = params_dict,\n",
        "    log = False\n",
        "    )\n",
        "\n",
        "# Prepare the training and validation datasets\n",
        "batch_size = 32\n",
        "xtrain, xval, ytrain, yval = genob.generate_data(num_reps=2000)\n",
        "train_data = tf.data.Dataset.from_tensor_slices((xtrain.astype(\"float32\"), ytrain))\n",
        "train_data = (\n",
        "      train_data.shuffle(len(ytrain))\n",
        "      .cache()\n",
        "      .batch(batch_size)\n",
        "      .prefetch(2)\n",
        ")\n",
        "\n",
        "val_data = tf.data.Dataset.from_tensor_slices((xval.astype(\"float32\"), yval))\n",
        "val_data = (\n",
        "      val_data.shuffle(len(yval))\n",
        "      .cache()\n",
        "      .batch(batch_size)\n",
        "      .prefetch(2)\n",
        ")\n",
        "\n",
        "# Prepare a list of genotype matrices from a range of parameter values\n",
        "# from msprime for testing\n",
        "xtest = genob.generate_testdata(num_reps=2000)\n",
        "test_data = tf.data.Dataset.from_tensor_slices((xtest.astype(\"float32\")))\n",
        "test_data = (\n",
        "      test_data\n",
        "      .cache()\n",
        "      .batch(batch_size)\n",
        "      .prefetch(2)\n",
        ")\n",
        "\n",
        "print('Data simulation finished')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "generating 2000 genotype matrices from msprime\n",
            "generating 2000 genotype matrices from msprime\n",
            "None\n",
            "X data shape is: (4000, 99, 128, 1)\n",
            "generating 2000 genotype matrices from msprime for testing\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-f0d02645aba7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;31m# Prepare a list of genotype matrices from a range of parameter values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;31m# from msprime for testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mxtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_testdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_reps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"float32\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m test_data = (\n",
            "\u001b[0;32m<ipython-input-3-ada6606b54bd>\u001b[0m in \u001b[0;36mgenerate_testdata\u001b[0;34m(self, num_reps, testlist)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msim_source\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'msprime'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m         \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_simulate_msprime_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-ada6606b54bd>\u001b[0m in \u001b[0;36m_simulate_msprime_list\u001b[0;34m(self, param_vals, seed, gauss)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m       \u001b[0;31m# For each tree sequence output from the simulation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m         \u001b[0mmat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resize_from_ts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/msprime/simulations.py\u001b[0m in \u001b[0;36m_replicate_generator\u001b[0;34m(sim, mutation_generator, num_replicates, provenance_dict, end_time)\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0mprovenance_record\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprovenance_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_replicates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m         \u001b[0msim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0mtree_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tree_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmutation_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprovenance_record\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mtree_sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/msprime/simulations.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, end_time)\u001b[0m\n\u001b[1;32m    705\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mll_sim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ll_representation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m         \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mend_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mll_sim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mll_sim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalise_tables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Egihlx4_WM0C"
      },
      "source": [
        "Building the MCMCGAN class object, and training the discriminator with the training and validation data that we have generated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUkLUTP7QHln"
      },
      "source": [
        "# Prepare the optimizer and loss function\n",
        "loss_fn = keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "opt = keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
        "\n",
        "model = 18\n",
        "epochs = 10\n",
        "\n",
        "mcmcgan = MCMCGAN(genob=genob, kernel_name='hmc', calibrated=True)\n",
        "\n",
        "mcmcgan.build_discriminator(\n",
        "    model, in_shape=(genob.num_samples, genob.fixed_dim, 1))\n",
        "mcmcgan.discriminator.compile(\n",
        "    optimizer=opt,\n",
        "    loss=loss_fn,\n",
        "    metrics = ['accuracy'])\n",
        "\n",
        "training = mcmcgan.discriminator.fit(\n",
        "    train_data, None, batch_size, epochs, validation_data=val_data,\n",
        "    shuffle=True)\n",
        "\n",
        "# Save the keras model\n",
        "mcmcgan.discriminator.summary(line_length=75, positions=[.58, .86, .99, .1])\n",
        "filename = f'D{model}_trained_{epochs}e.h5'\n",
        "mcmcgan.discriminator.save(filename)\n",
        " \n",
        "# Save the genotype builder object\n",
        "with open('genob.pkl', 'wb') as obj:\n",
        "    pickle.dump(genob, obj, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BE5NZ9BVVtwl"
      },
      "source": [
        "Run the next chunk only to load another discriminiator model saved as h5 or another pickle file with a genobuilder object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkdfPdjoGGu_"
      },
      "source": [
        "# Load another keras model and genotype builder\n",
        "keras.backend.clear_session()\n",
        "with open('genob.pkl', 'rb') as obj:\n",
        "  genob = pickle.load(obj)\n",
        "filename = 'D18_trained_20e.h5'\n",
        "mcmcgan = MCMCGAN(genob=genob, kernel_name='nuts', calibrated=True)\n",
        "mcmcgan.load_discriminator(filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woyJY3ThWXVi"
      },
      "source": [
        "Run the MCMC-GAN training and loop through the training iterations:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pefq4bdR_Su8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "46f110aa-def4-4a12-8115-b89adb207c11"
      },
      "source": [
        "mcmcgan.discriminator.run_eagerly = True\n",
        "tf.config.run_functions_eagerly(True)\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "n_reps = 2000\n",
        "max_num_iters = 10\n",
        "convergence = False\n",
        "it = 1\n",
        "\n",
        "# Initial guess must always be a float, otherwise with an int there are errors\n",
        "initial_guesses = tf.constant([-., -8., 4.])\n",
        "mcmcgan.setup_mcmc(\n",
        "                  num_mcmc_results=100,\n",
        "                  num_burnin_steps=30,\n",
        "                  initial_guess=initial_guesses\n",
        "                   )\n",
        "\n",
        "while convergence == False and max_num_iters != it:\n",
        "\n",
        "    start_t = time.time()\n",
        "\n",
        "    # Uncalibrated kernels doesn't converge to the desired distribution.\n",
        "    # MetropolisHastings(UncalibratedHamiltonianMonteCarlo(...)) is functionally\n",
        "    # the same as HamiltonianMonteCarlo(...).\n",
        "    print('Starting the MCMC sampling chain')\n",
        "    sample_mean, sample_stddev, is_accepted, log_acc_rate = mcmcgan.run_chain()\n",
        "    print(f'Is accepted: {is_accepted}, acc_rate: {log_acc_rate}')\n",
        "\n",
        "    # Trace plots\n",
        "    colors = ['b', 'g', 'r']\n",
        "    true_vals = [-9, -8, 4]\n",
        "    sns.set_style(\"darkgrid\")\n",
        "    for i in range(3):\n",
        "      plt.plot(mcmcgan.samples[:, i], c=colors[i], alpha=.3)\n",
        "      plt.hlines(true_vals[i], 0, len(mcmcgan.samples), zorder=4,\n",
        "                 color=colors[i], label=\"${}$\".format(i))\n",
        "    plt.legend(['recombination rate', 'mutation rate', 'effective size'])\n",
        "    plt.xlabel('Accepted samples')\n",
        "    plt.ylabel('Values in log scale')\n",
        "    plt.title(f'Trace plot of {mcmcgan.kernel_name} samples for it ' \\\n",
        "              f'{it}. Acc. rate: {is_accepted:.3f}')\n",
        "    plt.savefig(f'./results/trace_mcmcgan_' \\\n",
        "                f'{mcmcgan.kernel_name}_it{it}_joint.png')\n",
        "    plt.show()\n",
        "    plt.clf()\n",
        "\n",
        "    # Histogram of samples\n",
        "    for i in range(3):\n",
        "      sns.distplot(mcmcgan.samples[:, i], color=colors[i])\n",
        "    ymax = plt.ylim()[1]\n",
        "    for i in range(3):\n",
        "      plt.vlines(true_vals[i], 0, ymax, color=colors[i])\n",
        "    plt.ylim(0, ymax)\n",
        "    plt.legend(['recombination rate', 'mutation rate', 'effective size'])\n",
        "    plt.xlabel('Values in log scale')\n",
        "    plt.ylabel('Density')\n",
        "    plt.title(f\"{mcmcgan.kernel_name} samples for iteration {it}\")\n",
        "    plt.savefig(f'./results/mcmcgan_{mcmcgan.kernel_name}_it{it}_joint.png')\n",
        "    plt.show()\n",
        "    plt.clf()\n",
        "\n",
        "    guesses=[]\n",
        "\n",
        "    for p in mcmcgan.genob.params.values():\n",
        "      mean = np.mean(mcmcgan.samples[:, p.idx])\n",
        "      std = np.std(mcmcgan.samples[:, p.idx])\n",
        "      print(f'{p.name} samples with mean {mean} and std {std}')\n",
        "      p.set_gauss(mean, std)\n",
        "      guesses.append(mean)\n",
        "\n",
        "    mcmcgan.initial_guess = tf.constant(guesses)\n",
        "\n",
        "    # Prepare the training and validation datasets\n",
        "    xtrain, xval, ytrain, yval = mcmcgan.genob.generate_data(n_reps, gauss=True)\n",
        "    train_data = tf.data.Dataset.from_tensor_slices(\n",
        "                      (xtrain.astype(\"float32\"), ytrain))\n",
        "    train_data = (\n",
        "          train_data.shuffle(len(ytrain))\n",
        "          .cache()\n",
        "          .batch(batch_size)\n",
        "          .prefetch(2)\n",
        "    )\n",
        "\n",
        "    val_data = tf.data.Dataset.from_tensor_slices((xval.astype(\"float32\"), yval))\n",
        "    val_data = (\n",
        "          val_data.shuffle(len(yval))\n",
        "          .cache()\n",
        "          .batch(batch_size)\n",
        "          .prefetch(2)\n",
        "    )\n",
        "\n",
        "\n",
        "    xtest, param_values = mcmcgan.genob.generate_testdata(num_reps=2000)\n",
        "    test_data = tf.data.Dataset.from_tensor_slices((xtest.astype(\"float32\")))\n",
        "    test_data = (\n",
        "          test_data\n",
        "          .cache()\n",
        "          .batch(batch_size)\n",
        "          .prefetch(2)\n",
        "    )\n",
        "\n",
        "\n",
        "    mcmcgan.discriminator.fit(\n",
        "        train_data, None, batch_size, epochs, validation_data=val_data,\n",
        "        shuffle=True)\n",
        "\n",
        "    it += 1\n",
        "    if training.history['accuracy'][-1] < 0.55:\n",
        "    \tprint('convergence')\n",
        "    \tconvergence = True\n",
        "\n",
        "    t = time.time() - start_t\n",
        "    print(f'A single iteration of the MCMC-GAN took {t} seconds')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting the MCMC sampling chain\n",
            "0.999965966\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:3350: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
            "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.999999821\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "0.915086865\n",
            "0.908159256\n",
            "0.623226464\n",
            "0.632156849\n",
            "out\n",
            "out\n",
            "1\n",
            "1\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "1\n",
            "1\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "0.865882397\n",
            "0.966250956\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "0.20145081\n",
            "0.262120485\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "0.968753815\n",
            "0.92477107\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "1\n",
            "1\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "1\n",
            "1\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "0.101169996\n",
            "0.0406088345\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "1\n",
            "1\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "0.027886197\n",
            "0.0710303485\n",
            "6.08533834e-10\n",
            "8.89253671e-10\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "1\n",
            "1\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "5.07307391e-07\n",
            "2.47242525e-07\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "0.302428\n",
            "0.26469022\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "1\n",
            "1\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "1\n",
            "1\n",
            "0.25611186\n",
            "0.41503343\n",
            "out\n",
            "out\n",
            "1\n",
            "1\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "1\n",
            "1\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "1\n",
            "1\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "1\n",
            "1\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "1\n",
            "1\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "1\n",
            "1\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "0.999998569\n",
            "0.999998689\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0.999999821\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "0.999164522\n",
            "0.997353613\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "out\n",
            "out\n",
            "0.999999762\n",
            "0.994514465\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "1\n",
            "1\n",
            "0.999952495\n",
            "0.957425594\n",
            "out\n",
            "out\n",
            "1\n",
            "1\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "1\n",
            "1\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "2.80119554e-08\n",
            "1.03015534e-08\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "1\n",
            "1\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "1\n",
            "1\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "1\n",
            "1\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "out\n",
            "Is accepted: 0.05000000074505806, acc_rate: -inf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-17c1a8abc8bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Values in log scale'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Trace plot of {mcmcgan.kernel_name} samples for it '\u001b[0m               \u001b[0;34mf'{it}. Acc. rate: {is_accepted:.3f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'./results_joint/trace_mcmcgan_'\u001b[0m                 \u001b[0;34mf'{mcmcgan.kernel_name}_it{it}_joint.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# need this if 'transparent=True' to reset colors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[1;32m   2201\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_visible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframeon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2203\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2205\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mframeon\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2124\u001b[0m                     \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2125\u001b[0m                     \u001b[0mbbox_inches_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_bbox_inches_restore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2126\u001b[0;31m                     **kwargs)\n\u001b[0m\u001b[1;32m   2127\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2128\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrestore_bbox\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_renderer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_file_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m                 _png.write_png(renderer._renderer, fh, self.figure.dpi,\n\u001b[1;32m    537\u001b[0m                                metadata={**default_metadata, **metadata})\n",
            "\u001b[0;32m/usr/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36mopen_file_cm\u001b[0;34m(path_or_file, mode, encoding)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mopen_file_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[0;34mr\"\"\"Pass through file objects and context-manage `.PathLike`\\s.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m     \u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_filehandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopened\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36mto_filehandle\u001b[0;34m(fname, flag, return_opened, encoding)\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbz2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBZ2File\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'seek'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './results_joint/trace_mcmcgan_hmc_it1_joint.png'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}